{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8be583-d1c4-478e-92bd-e0df10225a9f",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf65438d-5b53-4b0e-b99d-8d9d8f4c7742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url                                0\n",
      "address                            0\n",
      "name                               0\n",
      "online_order                       0\n",
      "book_table                         0\n",
      "rate                            7775\n",
      "votes                              0\n",
      "phone                           1208\n",
      "location                          21\n",
      "rest_type                        227\n",
      "dish_liked                     28078\n",
      "cuisines                          45\n",
      "approx_cost(for two people)      346\n",
      "reviews_list                       0\n",
      "menu_item                          0\n",
      "listed_in(type)                    0\n",
      "listed_in(city)                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"zomato.db\")\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "df = pd.read_sql(\"SELECT * FROM zomato_restaurants;\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0b98b-5aa4-41fb-88aa-3560cfc906ac",
   "metadata": {},
   "source": [
    "# Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cd9766-ace4-457c-b3bc-5c928b011d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns={\n",
    "    'approx_cost(for two people)': 'cost',\n",
    "    'listed_in(type)': 'type',\n",
    "    'listed_in(city)': 'city'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cfe70b-5303-4054-a213-e30f841d2c92",
   "metadata": {},
   "source": [
    "# Drop unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0282cd6-a2c3-4f57-beda-e135ebb0feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and drop duplicate columns\n",
    "df.duplicated().sum()\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "950a7306-10f7-4814-b32c-d3cc98adae0f",
   "metadata": {},
   "source": [
    "# OPTIONAL WAY\n",
    "# Define a length threshold\n",
    "max_length = 100\n",
    "\n",
    "# Count how many columns exceed the character limit for each row\n",
    "long_text_count = df.apply(lambda row: (row.astype(str).str.len() > max_length).sum(), axis=1)\n",
    "\n",
    "# Set threshold (e.g., if more than 70% of columns have long text)\n",
    "threshold = int(0.7 * len(df.columns))\n",
    "\n",
    "# Remove rows where most columns exceed the threshold\n",
    "df = df[long_text_count <= threshold]\n",
    "\n",
    "# Reset index after removal\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02bb3d21-4049-4836-a4c8-06ee49a564cb",
   "metadata": {},
   "source": [
    "# OPTIONAL WAY\n",
    "# check and drop duplicate columns\n",
    "duplicate_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "print(\"Duplicate Columns:\", duplicate_columns)\n",
    "\n",
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcf34d2-15b4-4161-a8c9-fc2ba56dac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location and cuisines is fixed by dropping rows since there is only 21 rows\n",
    "df.dropna(subset=['location', 'cuisines'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc290e77-48c3-4821-afa6-a58cf53a25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(columns=['url','address', 'phone', 'reviews_list','menu_item'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9043ff52-3769-470a-9ef2-91bcb5693867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with excessive text removed. New dataset shape: (51672, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with excessive text removed. New dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abea7c-f54e-484c-900d-e7ab8e4bb3db",
   "metadata": {},
   "source": [
    "# Restructure data presentation & data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa3eb5f-8282-4291-8c79-516f0e772d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            object\n",
      "online_order    object\n",
      "book_table      object\n",
      "rate            object\n",
      "votes            int64\n",
      "location        object\n",
      "rest_type       object\n",
      "dish_liked      object\n",
      "cuisines        object\n",
      "cost            object\n",
      "type            object\n",
      "city            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check and change data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd792886-5932-4fe0-a80b-01c9ed2d5f0d",
   "metadata": {},
   "source": [
    "# Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da06ef98-c5ce-4302-bb46-f479b69b8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace string 'None' and other non-standard missing values with np.nan\n",
    "df.replace([\"None\", \"nan\", \"NaN\"], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4591b1db-9e5c-4389-af39-a07b2f20d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert online order and book table [1 for yes, 0 for no, 2 for irrelevant]\n",
    "def map_yes_no_irrelevant(value):\n",
    "    if value == \"Yes\":\n",
    "        return 1\n",
    "    elif value == \"No\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Apply the function to both columns\n",
    "df['online_order'] = df['online_order'].apply(map_yes_no_irrelevant).astype(int)\n",
    "df['book_table'] = df['book_table'].apply(map_yes_no_irrelevant).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec60fa3-2bab-4188-8ff7-b727ccc63ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with numerics [-1 for irrelevant]\n",
    "\n",
    "# Function to clean numeric columns and replace non-numeric values with median\n",
    "def clean_numeric_column(series, fill_with_median=True):\n",
    "    series = series.astype(str).str.replace(',', '', regex=True)  \n",
    "    series = pd.to_numeric(series, errors='coerce')  \n",
    "    \n",
    "    if fill_with_median:\n",
    "        median_value = series.median()\n",
    "        series = series.fillna(median_value)\n",
    "    else:  \n",
    "        series = series.fillna(-1)\n",
    "    \n",
    "    return series\n",
    "\n",
    "# Extract numeric part from 'rate' and clean\n",
    "df['rate'] = df['rate'].astype(str).str.extract(r'([\\d.]+)')\n",
    "df['rate'] = clean_numeric_column(df['rate'], fill_with_median=True)\n",
    "\n",
    "# Clean 'cost' column (remove commas and fill with median)\n",
    "df['cost'] = clean_numeric_column(df['cost'], fill_with_median=True).astype(int)\n",
    "\n",
    "# Clean 'votes' column (remove commas and replace non-numeric with -1)\n",
    "df['votes'] = clean_numeric_column(df['votes'], fill_with_median=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e90fd690-e6e0-43bf-a8f0-5279d8321e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with missing categorical values\n",
    "df[['dish_liked', 'rest_type']] = df[['dish_liked', 'rest_type']].fillna({'dish_liked': \"Not Available\", 'rest_type': \"Other\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b706366d-438f-4a0b-937f-d7e62a2b16ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid city names have been replaced with 'Not Available'.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of valid city names\n",
    "valid_cities = [\n",
    "    \"Church Street\", \"Brigade Road\", \"MG Road\", \"Lavelle Road\", \"Residency Road\",\n",
    "    \"Indiranagar\", \"Old Airport Road\", \"Whitefield\", \"Malleshwaram\", \"Frazer Town\",\n",
    "    \"Bellandur\", \"Sarjapur Road\", \"Koramangala 4th Block\", \"Koramangala 5th Block\",\n",
    "    \"Brookefield\", \"Koramangala 6th Block\", \"Koramangala 7th Block\", \"Marathahalli\",\n",
    "    \"Electronic City\", \"BTM\", \"HSR\", \"Rajajinagar\", \"Kalyan Nagar\", \"Kammanahalli\",\n",
    "    \"Jayanagar\", \"JP Nagar\", \"New BEL Road\", \"Bannerghatta Road\", \"Basavanagudi\",\n",
    "    \"Banashankari\"\n",
    "]\n",
    "\n",
    "# Fill missing values in 'city' safely\n",
    "df['city'] = df['city'].fillna(\"Not Available\")\n",
    "\n",
    "# Replace invalid city names with \"Not Available\" safely\n",
    "df['city'] = df['city'].apply(lambda x: x if x in valid_cities else \"Not Available\")\n",
    "\n",
    "print(\"Invalid city names have been replaced with 'Not Available'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a1493c9-9b35-4865-b754-d053fbf12bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            0\n",
      "online_order    0\n",
      "book_table      0\n",
      "rate            0\n",
      "votes           0\n",
      "location        0\n",
      "rest_type       0\n",
      "dish_liked      0\n",
      "cuisines        0\n",
      "cost            0\n",
      "type            0\n",
      "city            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verify missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b2ba70-bd7a-45a5-b5b6-b1c8ca9ef829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name             object\n",
      "online_order      int32\n",
      "book_table        int32\n",
      "rate            float64\n",
      "votes             int32\n",
      "location         object\n",
      "rest_type        object\n",
      "dish_liked       object\n",
      "cuisines         object\n",
      "cost              int32\n",
      "type             object\n",
      "city             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9f81f-e43f-44d3-993f-436e2419b060",
   "metadata": {},
   "source": [
    "# Save cleaned data in SQLite & Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01a77614-ed4e-4ca7-90f6-d60286b5f59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete! Cleaned data saved as 'zomato_cleaned'.\n"
     ]
    }
   ],
   "source": [
    "# cleaned data\n",
    "conn = sqlite3.connect(\"zomato.db\")\n",
    "df.to_sql(\"zomato_cleaned\", conn, if_exists=\"replace\", index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"Data cleaning complete! Cleaned data saved as 'zomato_cleaned'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b107b42-069d-4c4d-8d48-900006572a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved as 'zomato_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "# to save cleaned data into working directory\n",
    "conn = sqlite3.connect(\"zomato.db\")\n",
    "df_cleaned = pd.read_sql(\"SELECT * FROM zomato_cleaned;\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Save to CSV\n",
    "df_cleaned.to_csv(\"zomato_cleaned.csv\", index=False)\n",
    "print(\"Cleaned data saved as 'zomato_cleaned.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
